length(data_clean)
data_clean <- data_clean[8:length(data_clean)]
modFit <- train(classe ~ ., data = data_clean, method = "rtf", prox = TRUE)
modFit <- train(classe ~ ., data = data_clean, method = "rf", prox = TRUE)
summary(modFit)
warnings()
data_clean
gc()
modFit <- train(classe ~ ., data = data_clean, method = "rf", prox = TRUE)
warnings()
modFit <- train(classe ~ ., data = training, method = "rf", prox = TRUE)
inTrain <- createDataPartition(y = data_clean$classe, p = 0.75, list = FALSE)
training <- trainingDataclean[inTrain,]
testing <- trainingDataclean[-inTrain,]
data_ <- read.csv("../data/pml-training.csv", na.strings= c("NA",""," "))
#data_ <- read.csv("../data/pml-training.csv")
# clean the training data by removing columns with NAs etc
data_NAs <- apply(data_, 2, function(x) {sum(is.na(x))})
data_clean <- data_[,which(data_NAs == 0)]
# remove identifier columns such as name, timestamps etc
data_clean <- data_clean[8:length(data_clean)]
# split the cleaned data into training and testing
inTrain <- createDataPartition(y = data_clean$classe, p = 0.75, list = FALSE)
training <- trainingDataclean[inTrain,]
testing <- trainingDataclean[-inTrain,]
# split the cleaned data into training and testing
inTrain <- createDataPartition(y = data_clean$classe, p = 0.75, list = FALSE)
training <- data_clean [inTrain,]
testing <- data_clean [-inTrain,]
modFit <- train(classe ~ ., data = training, method = "rf", prox = TRUE)
warnings
warnings()
names(data_clean)
dim(data_clean)
# split the cleaned data into training and testing
inTrain <- createDataPartition(y = data_clean$classe, p = 0.7, list = FALSE)
training <- data_clean [inTrain,]
testing <- data_clean [-inTrain,]
correlMatrix <- cor(training[, -53])
corrplot(correlMatrix, order = "FPC", method = "circle", type = "lower", tl.cex = 0.8,  tl.col = rgb(0, 0, 0))
library(randomForest)
library(caret)
library(kernlab)
library(randomForest)
library(Hmisc)
library(corrplot)
install.packages("corrplot")
correlMatrix <- cor(training[, -53])
corrplot(correlMatrix, order = "FPC", method = "circle", type = "lower", tl.cex = 0.8,  tl.col = rgb(0, 0, 0))
library(corrplot)
correlMatrix <- cor(training[, -53])
corrplot(correlMatrix, order = "FPC", method = "circle", type = "lower", tl.cex = 0.8,  tl.col = rgb(0, 0, 0))
preProc <- preProcess(training[, -53], method = "pca", thresh = 0.99)
trainPC <- predict(preProc, training[, -53])
validationTestPC <- predict(preProc, testing[, -53])
dim(training)
modelFit <- train(training$classe ~ ., method = "rf", data = trainPC,
trControl = trainControl(method = "cv", number = 4), importance = TRUE)
trainPC <- predict(preProc, training[, -53])
validationTestPC <- predict(preProc, testing[, -53])
trainPC
dim(training)
preProc
validationTestPC <- predict(preProc, testing[, -53])
validationTestPC
summar9validationTestPC )
summary(validationTestPC )
model3 <- randomForest(classe ~ ., data = training, ntree = 1024)
gc()
modelFit1 <- suppressWarnings(train(classe ~., data = training, method = "rf",
trControl = trainControl(method = "cv", number = 4, allowParallel = TRUE), preProcess = "pca"))
install.packages("randomForest")
install.packages("randomForest")
?randomForest
library(randomForest)
?randomForest
trControl = trainControl(method = "cv", number = 4, allowParallel = TRUE,verboseIter = TRUE)
modelFit1 <- suppressWarnings(train(classe ~., data = training, method = "rf",
trControl = trainControl(method = "cv", number = 4, allowParallel = TRUE), preProcess = "pca"))
library(caret)
library(kernlab)
library(randomForest)
library(Hmisc)
library(corrplot)
modelFit1 <- suppressWarnings(train(classe ~., data = training, method = "rf",
trControl = trainControl(method = "cv", number = 4, allowParallel = TRUE), preProcess = "pca"))
install.packages("doParallel")
model3 <- randomForest(classe ~ ., data = training, ntree = 1024)
gc()
model <- randomForest(classe ~ ., data = training)
model
model <- randomForest(classe ~ ., data = training, ntree = 10)
model
model <- randomForest(classe ~ ., data = training)
model
finalprediction <- predict(model, testing)
finalprediction
model
print(confusionMatrix(testing$classe, model, digits = 3)
)
print(confusionMatrix(testing$classe, model), digits = 3)
?confusionMatrixc
?confusionMatrix
predict(testing, model)
predsi<-predict(model,testing)
predict(model, testing
)
confusionMatrix(predict(model, testing), crossval$classe)
confusionMatrix(predict(model, testing))
confusionMatrix(predict(model, testing), testing$classe)
data_test <- read.csv("../data/pml-training.csv")
confusionMatrix(predict(model, testing), data_test$classe)
data_clean <- data_[,which(data_NAs == 0)]
data_test_clean <- data_test[,which(data_test_NAs == 0)]
data_test_clean <- data_test_clean[8:length(data_testclean)]
data_test <- read.csv("../data/pml-training.csv")
data_test <- read.csv("../data/pml-training.csv")
data_test_NAs <- apply(data_test, 2, function(x) {sum(is.na(x))})
data_test_clean <- data_[,which(data_test_NAs == 0)]
confusionMatrix(predict(model, testing), data_test_clean$classe)
predictModel<-predict(model, data_test_clean)
predictModel
predictModel<-predict(model, data_test_clean)
predictModel[1:10]
predictModel<-predict(model, data_test_clean)
predictModel[1:20]
data_test_clean
predictModel[1:20]
identical(data_test_clean, data_test_clean$classe)
data.frame(data_test_clean, data_test_clean$classe)
data.frame(predictModel), data_test_clean$classe)
data.frame(predictModel, data_test_clean$classe)
identical(predictModel, data_test_clean$classe)
a <- data.frame(predictModel, data_test_clean$classe)
a[1:100]
a[, 1:100]
a[1:100, ]
a[500:1000, ]
a[2000:3000, ]
dim(a)
dim(data_test)
a[5000:7000, ]
confusionMatrix(a)
finalprediction <- predict(model, testing)
finalprediction
# read the csv file for training
data_test <- read.csv("../data/pml-training.csv", na.strings= c("NA",""," "))
# clean the training data by removing columns with NAs etc
data_test_NAs <- apply(data_test, 2, function(x) {sum(is.na(x))})
data_test_clean <- data_test[,which(data_test_NAs == 0)]
# remove identifier columns such as name, timestamps etc
data_test_clean <- ddata_test_clean[8:length(data_test_clean)]
# split the cleaned data into training and testing
inTrain <- createDataPartition(y = data_test_clean$classe, p = 0.7, list = FALSE)
training <- data_clean [inTrain,]
crossval <- data_clean [-inTrain,]
# plot a correlation matrix
correlMatrix <- cor(training[, -53])
corrplot(correlMatrix, order = "FPC", method = "circle", type = "lower", tl.cex = 0.8,  tl.col = rgb(0, 0, 0))
# preprocess all the variables (except the outcome)
# preProc <- preProcess(training[, -53], method = "pca", thresh = 0.99)
# applying post processed data to test set
# trainPC <- predict(preProc, training[, -53])
# validationTestPC <- predict(preProc, testing[, -53])
model <- randomForest(classe ~ ., data = training)
finalprediction <- predict(model, crossval)
data_test <- read.csv("../data/pml-training.csv")
data_test_NAs <- apply(data_test, 2, function(x) {sum(is.na(x))})
data_test_clean <- data_[,which(data_test_NAs == 0)]
# remove identifier columns such as name, timestamps etc
data_clean <- data_clean[8:length(data_clean)]
predictModel <- predict(model, data_test_clean)
predictModel[1:20]
confusionMatrix(predict(model, testing), testing$classe)
confusionMatrix(predict(model, testing), data_test_clean$classe)
# clean the training data by removing columns with NAs etc
data_test_NAs <- apply(data_test, 2, function(x) {sum(is.na(x))})
data_test_clean <- data_test[,which(data_test_NAs == 0)]
# remove identifier columns such as name, timestamps etc
data_test_clean <- data_test_clean[8:length(data_test_clean)]
# split the cleaned data into training and testing
inTrain <- createDataPartition(y = data_test_clean$classe, p = 0.7, list = FALSE)
training <- data_clean [inTrain,]
crossval <- data_clean [-inTrain,]
# plot a correlation matrix
correlMatrix <- cor(training[, -53])
corrplot(correlMatrix, order = "FPC", method = "circle", type = "lower", tl.cex = 0.8,  tl.col = rgb(0, 0, 0))
# preprocess all the variables (except the outcome)
# preProc <- preProcess(training[, -53], method = "pca", thresh = 0.99)
# applying post processed data to test set
# trainPC <- predict(preProc, training[, -53])
# validationTestPC <- predict(preProc, testing[, -53])
model <- randomForest(classe ~ ., data = training)
finalprediction <- predict(model, crossval)
data_test <- read.csv("../data/pml-training.csv")
data_test_NAs <- apply(data_test, 2, function(x) {sum(is.na(x))})
data_test_clean <- data_[,which(data_test_NAs == 0)]
# remove identifier columns such as name, timestamps etc
data_clean <- data_clean[8:length(data_clean)]
predictModel <- predict(model, data_test_clean)
predictModel[1:20]
confusionMatrix(predict(model, testing), testing$classe)
confusionMatrix(predict(model, testing), data_test_clean$classe)
predictModel <- predict(model, data_test_clean)
summary(predictModel)
summary(data_test_clean$classe)
confusioMatrix(predictModel, data_test_clean$classe)
data_training <- read.csv("../data/pml-training.csv", na.strings= c("NA",""," "))
# clean the training data by removing columns with NAs etc
data_training_NAs <- apply(data_training, 2, function(x) {sum(is.na(x))})
data_training_clean <- data_test[,which(data_training_NAs == 0)]
# remove identifier columns such as name, timestamps etc
data_training_clean <- data_training_clean[8:length(data_training_clean)]
# split the cleaned data into training and testing
inTrain <- createDataPartition(y = data_training_clean$classe, p = 0.7, list = FALSE)
training <- data_clean [inTrain,]
crossval <- data_clean [-inTrain,]
# plot a correlation matrix
correlMatrix <- cor(training[, -53])
corrplot(correlMatrix, order = "FPC", method = "circle", type = "lower", tl.cex = 0.8,  tl.col = rgb(0, 0, 0))
# fit a model to predict the classe using everything else as a predictor
model <- randomForest(classe ~ ., data = training)
data_training <- read.csv("../data/pml-training.csv", na.strings= c("NA",""," "))
# clean the training data by removing columns with NAs etc
data_training_NAs <- apply(data_training, 2, function(x) {sum(is.na(x))})
data_training_clean <- data_test[,which(data_training_NAs == 0)]
# remove identifier columns such as name, timestamps etc
data_training_clean <- data_training_clean[8:length(data_training_clean)]
# split the cleaned data into training and testing
inTrain <- createDataPartition(y = data_training_clean$classe, p = 0.7, list = FALSE)
training <- data_clean [inTrain,]
crossval <- data_clean [-inTrain,]
# plot a correlation matrix
correlMatrix <- cor(training[, -53])
corrplot(correlMatrix, order = "FPC", method = "circle", type = "lower", tl.cex = 0.8,  tl.col = rgb(0, 0, 0))
# fit a model to predict the classe using everything else as a predictor
model <- randomForest(classe ~ ., data = training)
# read the csv files for training and testing
data_training <- read.csv("../data/pml-training.csv", na.strings= c("NA",""," "))
# clean the training data by removing columns with NAs etc
data_training_NAs <- apply(data_training, 2, function(x) {sum(is.na(x))})
data_training_clean <- data_training_clean[,which(data_training_NAs == 0)]
# remove identifier columns such as name, timestamps etc
data_training_clean <- data_training_clean[8:length(data_training_clean)]
# split the cleaned data into training and testing
inTrain <- createDataPartition(y = data_training_clean$classe, p = 0.7, list = FALSE)
training <- data_clean [inTrain,]
crossval <- data_clean [-inTrain,]
# plot a correlation matrix
correlMatrix <- cor(training[, -53])
corrplot(correlMatrix, order = "FPC", method = "circle", type = "lower", tl.cex = 0.8,  tl.col = rgb(0, 0, 0))
# fit a model to predict the classe using everything else as a predictor
model <- randomForest(classe ~ ., data = training)
# crossvalidate the model using the remaining 30% of data
finalprediction <- predict(model, crossval)
data_test <- read.csv("../data/pml-training.csv")
data_test_NAs <- apply(data_test, 2, function(x) {sum(is.na(x))})
data_test_clean <- data_[,which(data_test_NAs == 0)]
# remove identifier columns such as name, timestamps etc
data_clean <- data_clean[8:length(data_clean)]
# read the csv files for training and testing
data_training <- read.csv("../data/pml-training.csv", na.strings= c("NA",""," "))
# clean the training data by removing columns with NAs etc
data_training_NAs <- apply(data_training, 2, function(x) {sum(is.na(x))})
data_training_clean <- data_training_clean[,which(data_training_NAs == 0)]
# remove identifier columns such as name, timestamps etc
data_training_clean <- data_training_clean[8:length(data_training_clean)]
# split the cleaned data into training and testing
inTrain <- createDataPartition(y = data_training_clean$classe, p = 0.7, list = FALSE)
training <- data_clean [inTrain,]
crossval <- data_clean [-inTrain,]
# plot a correlation matrix
correlMatrix <- cor(training[, -53])
corrplot(correlMatrix, order = "FPC", method = "circle", type = "lower", tl.cex = 0.8,  tl.col = rgb(0, 0, 0))
# fit a model to predict the classe using everything else as a predictor
model <- randomForest(classe ~ ., data = training)
# crossvalidate the model using the remaining 30% of data
finalprediction <- predict(model, crossval)
data_test <- read.csv("../data/pml-training.csv")
data_test_NAs <- apply(data_test, 2, function(x) {sum(is.na(x))})
data_test_clean <- data_[,which(data_test_NAs == 0)]
# remove identifier columns such as name, timestamps etc
data_clean <- data_clean[8:length(data_clean)]
# read the csv files for training and testing
data_training <- read.csv("../data/pml-training.csv", na.strings= c("NA",""," "))
# clean the training data by removing columns with NAs etc
data_training_NAs <- apply(data_training, 2, function(x) {sum(is.na(x))})
data_training_clean <- data_training[,which(data_training_NAs == 0)]
# remove identifier columns such as name, timestamps etc
data_training_clean <- data_training_clean[8:length(data_training_clean)]
# split the cleaned data into training and testing
inTrain <- createDataPartition(y = data_training_clean$classe, p = 0.7, list = FALSE)
training <- data_clean [inTrain,]
crossval <- data_clean [-inTrain,]
# plot a correlation matrix
correlMatrix <- cor(training[, -53])
corrplot(correlMatrix, order = "FPC", method = "circle", type = "lower", tl.cex = 0.8,  tl.col = rgb(0, 0, 0))
# fit a model to predict the classe using everything else as a predictor
model <- randomForest(classe ~ ., data = training)
# crossvalidate the model using the remaining 30% of data
finalprediction <- predict(model, crossval)
# read the csv files for training and testing
data_training <- read.csv("../data/pml-training.csv", na.strings= c("NA",""," "))
# clean the training data by removing columns with NAs etc
data_training_NAs <- apply(data_training, 2, function(x) {sum(is.na(x))})
data_training_clean <- data_training[,which(data_training_NAs == 0)]
data_training_clean <- data_training_clean[8:length(data_training_clean)]
data_training_clean <- data_training_clean[8:length(data_training_clean)]
inTrain <- createDataPartition(y = data_training_clean$classe, p = 0.7, list = FALSE)
training <- data_clean [inTrain,]
crossval <- data_clean [-inTrain,]
# split the cleaned data into training and testing
inTrain <- createDataPartition(y = data_training_clean$classe, p = 0.7, list = FALSE)
training <- data_training_clean[inTrain,]
crossval <- data_training_clean[-inTrain,]
correlMatrix <- cor(training[, -53])
corrplot(correlMatrix, order = "FPC", method = "circle", type = "lower", tl.cex = 0.8,  tl.col = rgb(0, 0, 0))
# fit a model to predict the classe using everything else as a predictor
model <- randomForest(classe ~ ., data = training)
# crossvalidate the model using the remaining 30% of data
finalprediction <- predict(model, crossval)
data_test <- read.csv("../data/pml-training.csv")
data_test_NAs <- apply(data_test, 2, function(x) {sum(is.na(x))})
data_test_clean <- data_test[,which(data_test_NAs == 0)]
# remove identifier columns such as name, timestamps etc
data_test_clean <- data_test_clean[8:length(data_clean)]
predictModel <- predict(model, data_test_clean)
predictModel[1:20]
data_test <- read.csv("../data/pml-training.csv")
data_test_NAs <- apply(data_test, 2, function(x) {sum(is.na(x))})
data_test_clean <- data_test[,which(data_test_NAs == 0)]
# remove identifier columns such as name, timestamps etc
data_test_clean <- data_test_clean[8:length(data_test_clean)]
predictModel <- predict(model, data_test_clean)
predictModel[1:20]
correlMatrix <- cor(training[, -53])
corrplot(correlMatrix, order = "FPC", method = "circle", type = "lower", tl.cex = 0.8,  tl.col = rgb(0, 0, 0))
# fit a model to predict the classe using everything else as a predictor
model <- randomForest(classe ~ ., data = training)
# crossvalidate the model using the remaining 30% of data
finalprediction <- predict(model, crossval)
head(data_test$classe)
model
finalprediction
dim(data_training)
dim(data_test)
# apply the same treatment to the final testing data
data_test <- read.csv("../data/pml-testing.csv", na.strings= c("NA",""," "))
data_test_NAs <- apply(data_test, 2, function(x) {sum(is.na(x))})
data_test_clean <- data_test[,which(data_test_NAs == 0)]
data_test_clean <- data_test_clean[8:length(data_test_clean)]
predictModel <- predict(model, data_test_clean)
predictModel
correlMatrix <- cor(training[, -53])
training[, -53]
correlMatrix <- cor(data_training_clean[, -53])
correlMatrix <- cor(training[, -53])
length(training)
correlMatrix <- cor(training[, -46])
corrplot(correlMatrix, order = "FPC", method = "circle", type = "lower", tl.cex = 0.8,  tl.col = rgb(0, 0, 0))
length(training)
length(crossval)
correlMatrix <- cor(training[, -length(training)])
corrplot(correlMatrix, order = "FPC", method = "circle", type = "lower", tl.cex = 0.8,  tl.col = rgb(0, 0, 0))
predictCrossVal <- predict(model, crossval)
predictTest <- predict(model, data_test_clean)
predictTest
predictCrossVal <- predict(model, crossval)
predictTest <- predict(model, data_test_clean)
predictTest
confusionMatrix(predictCrossVal, data_test_clean$classe)
confusionMatrix(predict(model, data_test_clean), data_test_clean$classe)
predictCrossVal <- predict(model, crossval)
predictCrossVal
confusionMatrix(predictCrossVal, data_test_clean$classe)
predictCrossVal <- predict(model, crossval)
confusionMatrix(data_training_clean$classe, predictCrossVal)
predictCrossVal <- predict(model, crossval)
confusionMatrix(crossval$classe, predictCrossVal)
# read the csv files for training and testing
data_training <- read.csv("../data/pml-training.csv", na.strings= c("NA",""," "))
# clean the data by removing columns with NAs etc
data_training_NAs <- apply(data_training, 2, function(x) {sum(is.na(x))})
data_training_clean <- data_training[,which(data_training_NAs == 0)]
# remove identifier columns such as name, timestamps etc
data_training_clean <- data_training_clean[8:length(data_training_clean)]
# split the cleaned testing data into training and cross validation
inTrain <- createDataPartition(y = data_training_clean$classe, p = 0.7, list = FALSE)
training <- data_training_clean[inTrain, ]
crossval <- data_training_clean[-inTrain, ]
# plot a correlation matrix
correlMatrix <- cor(training[, -length(training)])
corrplot(correlMatrix, order = "FPC", method = "circle", type = "lower", tl.cex = 0.8,  tl.col = rgb(0, 0, 0))
# fit a model to predict the classe using everything else as a predictor
model <- randomForest(classe ~ ., data = training)
# crossvalidate the model using the remaining 30% of data
predictCrossVal <- predict(model, crossval)
confusionMatrix(crossval$classe, predictCrossVal)
# apply the same treatment to the final testing data
data_test <- read.csv("../data/pml-testing.csv", na.strings= c("NA",""," "))
data_test_NAs <- apply(data_test, 2, function(x) {sum(is.na(x))})
data_test_clean <- data_test[,which(data_test_NAs == 0)]
data_test_clean <- data_test_clean[8:length(data_test_clean)]
# predict the classes of the test set
predictTest <- predict(model, data_test_clean)
gc()
moedl
model
confusionMatrix(crossval$classe, predictCrossVal)
predictCrossVal
confusionMatrix(crossval$classe, predictCrossVal)
predictTest
summary(predictTest)
getwd()
setwd("../")
list.files()
data_training <- read.csv("../data/pml-training.csv", na.strings= c("NA",""," "))
list.files()
setwd("data")
data_training <- read.csv("../data/pml-training.csv", na.strings= c("NA",""," "))
plot(model)
plot(predictTest)
varImpPlot(model$finalModel)
class(model)
plot(model)
getTree(model)
getTree(model, 1)
model$finalModel
names(modeL)
names(model)
model$forest
plot(model$forest)
plot(model, log="y")
MDSplot(model, training$classe)
bc()
gc()
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
pml_write_files(answers)
list.files()
list.files()
getwd()
setwd("../")
pml_write_files(answers)
list.files()
pml_write_files(answers)
setwd("~/GitHub/Data-Scientist-MOOC/8 - Practical Machine Learning/Project/answers")
pml_write_files(answers)
setwd("~/GitHub/Data-Scientist-MOOC/8 - Practical Machine Learning/Project")
list.files()
predictTest
pml_write_files(predictTest)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.7, list = FALSE)
training <- data_training_clean[inTrain, ]
test <- data_training_clean[-inTrain, ]
training <- segmentationOriginal[inTrain, ]
test <- segmentationOriginal[-inTrain, ]
head(segmentationOriginal)
head(training)
test <- segmentationOriginal[inTrain, ]
training <- segmentationOriginal[-inTrain, ]
head(test)
gc()
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
# 1. Subset the data to a training set and testing set based on the Case variable in the data set.
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.7, list = FALSE)
test <- segmentationOriginal[inTrain, ]
training <- segmentationOriginal[-inTrain, ]
# 2. Set the seed to 125 and fit a CART model with the rpart method using all
# predictor variables and default caret settings.
train(data = subset(segmentationOriginal, Case == "Train")
)
?train
head(test)
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
summary(inTrain)
test <- segmentationOriginal[inTrain, ]
training <- segmentationOriginal[-inTrain, ]
test$Case
subset(SegmentationOriginal, Case == "Train")
subset(Segmentation, Case == "Train")
subset(SegmentationOriginal, Case == "Train")
subset(segmentationOriginal, Case == "Train")
train <- subset(segmentationOriginal, Case == "Train")
train$Case
test <- subset(segmentationOriginal, Case == "Test")
test$Case
rpartFit <- train(medv ~ ., , method = "rpart", data = train)
rpartFit <- train(Case ~ ., , method = "rpart", data = train)
rpartFit <- train(Case ~ ., , method = "rpart", data = train, tuneLength = 9)
modFit <- train(Case ~ ., data=training, method="rpart")
modFit$finalModel
modFit <- train(Case ~ ., data=training, method="rpart", TotalIntench2 = 23,000)
modFit$finalModel
modFit <- train(Case ~ ., data=training, method="rpart", TotalIntench2 = 23,000)
modFit$finalModel
modFit$finalModel
